alpha5Shape <- 3
alpha5Rate <- 1/(100*alpha5Shape)
# recall dvtotal ~ LogNormal(alpha6, alpha7)
# alpha6 ~ Normal(alpha6Mean, alpha6Var)
# alpha7 ~ InverseGamma(alpha7Shape, alpha7Rate)
alpha6Mean <- 3
alpha6Var <- .1
alpha7Shape <- 3
alpha7Rate <- 1/(.24*alpha7Shape)
# PRIORS FOR BETA (logistic regression coefficients)
meanLogRegIntercept <- -4.75
varIntercept <- 2
varBeta <- 2
# set up the tuning parameters for the proposal
numAlpha <- 7
d <- ncol(X) + numAlpha
alphaQCovMatDiag <- rep(.1, numAlpha)* (2.4^2)/d
#alphaQCovMatDiag <-  c(4.008890e-03, 1.820796e-03, 2.440956e-04, 4.502765e-02, 4.248805e-04, 7.921711e-05, 4.435642e-05)*(2.4^2)/d
betaQCovMat <- vcov(glm(outcome ~ ., data = dat, na.action = na.exclude)) * (2.4^2)/d
logPiUnNorm <- function(alpha, beta){
# calculates the prior for the alpha parameters (govern missing data),
# and for the beta parameters (govern the logistic regression)
nb <- length(beta)
dbeta(x = alpha[1], shape1 = shape1P, shape2 = shape2P, log = TRUE) +
dnorm(x = alpha[2], mean = alpha2Mean, sd = sqrt(alpha2Var), log = TRUE) +
dinvgamma(alpha[3], shape=alpha3Shape, rate = alpha3Rate, log = TRUE) +
dnorm(x = alpha[4], mean = alpha4Mean, sd = sqrt(alpha4Var), log = TRUE) +
dinvgamma(alpha[5], shape=alpha5Shape, rate = alpha5Rate, log = TRUE) +
dnorm(x = alpha[6], mean = alpha6Mean, sd = sqrt(alpha6Var), log = TRUE) +
dinvgamma(alpha[7], shape = alpha7Shape, rate = alpha7Rate, log = TRUE) +
dnorm(x = beta[1], mean = meanLogRegIntercept, sd = sqrt(varIntercept), log = TRUE) +
sum(dnorm(x = beta[2:(nb-1)], mean = 0, sd = sqrt(varBeta), log = TRUE))
}
propose_missdata_given_params <- function(alpha, beta){
# assuming:
# alpha = (p, meanheight, varheight, meanweight, varweight, mudvtotal, sigmaSqdDvTotal)
# beta = (intercept, age, sex1dummy, height, weight, seatpos13, seatpos21, seatpos22, seatpos23, dvtotal)
# draw missing data
# sex ~ bernoulli(alpha1)
# height ~ Normal(alpha2, alpha3)
# weight ~ Normal(alpha4, alpha5)
# dvtotal ~ Lognormal(alpha6, alpha7)
sex <- rbinom(n = numMissingEachGroup[1],
size=1,
alpha[1])
height <- rnorm(n = numMissingEachGroup[2],
mean=alpha[2],
sd = sqrt(alpha[3]))
weight <- rnorm(n = numMissingEachGroup[3],
mean = alpha[4],
sd = sqrt(alpha[5]))
dvtotal <- rlnorm(n = numMissingEachGroup[4],
meanlog = alpha[6],
sdlog = sqrt(alpha[7]))
return(list(sex = sex, height = height, weight = weight, dvtotal = dvtotal))
}
# full model matrix columns are as follows:
# intercept, age, sex1, height, weight, seatpos13, seatpos21, sseatpos22, seatpos23, dvtotal
# the argument here is assumed to be a list of vectors
logCondLike <- function(sex, height, weight, dvtotal, beta){
# insert simulated data into missing data spots
X <- as.data.frame(X)
X$sex1[is.na(X$sex1)] <- sex
X$height[is.na(X$height)] <- height
X$weight[is.na(X$weight)] <- weight
X$dvtotal[is.na(X$dvtotal)] <- dvtotal
stopifnot(sum(is.na(X))==0)
stopifnot(length(beta)==ncol(X))
# evaluate cond like
sum(dbinom(x = dat$outcome,
size = 1,
prob = inv.logit(as.matrix(X) %*% as.matrix(beta)),
log = TRUE))
}
getLogImpSampEst <- function(alphaVec, betaVec, N=100, par = T){
# using log-sum-exp trick
f <- function(purposelessArg){
Xmis <- propose_missdata_given_params(alphaVec, betaVec)
return(logCondLike(sex = Xmis$sex, height=Xmis$height, weight=Xmis$weight, dvtotal=Xmis$dvtotal, beta=betaVec))
}
if(par){
samps <- parSapply(cl, 1:N, f)
}else{
samps <- replicate(N, f())
}
m <- max(samps, na.rm = T)
if(is.infinite(m) && m < 0){
# cat("the maximum log-like was -infinity\n")
return(m)
}
ans <- log(sum(exp(samps - m))) + m - log(N)
# if(is.nan(ans)){
#   cat("ans is nan! ", ans, "\n")
#   cat("samps\n ", samps, "\n")
#   cat("alphas", alphaVec, "\n")
#   cat("betas", betaVec, "\n")
#   # sampleSimData <- f()
#   # cat("sample data:\n ")
#   # for(i in 1:length(sampleSimData)) cat(sampleSimData[[i]], "\n")
# }
return(ans)
}
# alpha = (p, meanheight, varheight, meanweight, varweight, mudvtotal, sigmaSqdDvTotal)
# transAlpha = (logit(p), meanheight, log(varheight), meanweight, log(varweight), mudvtotal, log(varDvTotal))
transAlpha <- function(alpha){
c(logit(alpha[1]), alpha[2], log(alpha[3]), alpha[4], log(alpha[5]), alpha[6], log(alpha[7]))
}
getAlpha <- function(transformedAlpha){
c(inv.logit(transformedAlpha[1]),
transformedAlpha[2],
exp(transformedAlpha[3]),
transformedAlpha[4],
exp(transformedAlpha[5]),
transformedAlpha[6],
exp(transformedAlpha[7]))
}
qSim <- function(oldAlpha, oldBeta){
# sample alphas
newAlpha <- getAlpha(mvrnorm(n=1, mu = transAlpha(oldAlpha), Sigma = diag(alphaQCovMatDiag)))
# sample betas
newBeta <- mvrnorm(n=1, mu=oldBeta, Sigma = betaQCovMat)
# return stuff
list(alphas = newAlpha, betas = newBeta)
}
logQEv <- function(oldAlpha, oldBeta, targetAlpha, targetBeta){
sum(dnorm(x = transAlpha(targetAlpha),
mean = transAlpha(oldAlpha),
sd = sqrt(alphaQCovMatDiag),
log = TRUE)) -
log(targetAlpha[1]) - log(1 - targetAlpha[1]) -
log(targetAlpha[3]) -
log(targetAlpha[5]) -
log(targetAlpha[7]) + # tODO this might be wrong because its the log of the std dev param
dmvnorm(x = targetBeta,
mean = oldBeta,
sigma = betaQCovMat,
log = TRUE)
}
getLogRatio <- function(oldAlpha, oldBeta, oldApproxLogLike, propAlpha, propBeta, propApproxLogLike){
res <- logPiUnNorm(alpha = propAlpha, beta = propBeta) - logPiUnNorm(alpha = oldAlpha, beta = oldBeta)
res <- res + propApproxLogLike - oldApproxLogLike #this can produce NaNs
res <- res + logQEv(oldAlpha = propAlpha, oldBeta = propBeta, targetAlpha = oldAlpha, targetBeta = oldBeta) -
logQEv(oldAlpha = oldAlpha, oldBeta = oldBeta, targetAlpha = propAlpha, targetBeta = propBeta)
return(res)
}
do1Iter <- function(oldSamp, N){
propParams <- qSim(oldSamp$alphas, oldSamp$betas)
newApproxLL <- getLogImpSampEst(propParams$alphas, propParams$betas, N)
logratio <- getLogRatio(oldAlpha = oldSamp$alphas,
oldBeta = oldSamp$betas,
oldApproxLogLike = oldSamp$LLEst,
propAlpha = propParams$alphas,
propBeta = propParams$betas,
propApproxLogLike = newApproxLL)
if(log(runif(1)) < logratio){
cat("accepting!")
list(alphas = propParams$alphas, betas = propParams$betas, LLEst = newApproxLL)
}else{
oldSamp
}
}
DOPAR
DOPAR=F
ptm <- proc.time() # for timing the whole thing
N <- 50 # number of importance samples at each iteration
startAlpha <- c(.53, 171, 30, 74, 68, 3, 1) #(p, meanheight, varheight, meanweight, varweight, mudvtotal, sigmaSqdDvTotal)
startBeta <- coefficients(glm(outcome ~ ., data = dat, na.action = na.exclude))
if(DOPAR){
cl <- makeCluster(no_cores, type="FORK")
clusterExport(cl, list("propose_missdata_given_params"))
}
startLogLikeEst <- getLogImpSampEst(startAlpha, startBeta, N, par = DOPAR)
samp1 <- list(alphas = startAlpha, betas = startBeta, LLEst = startLogLikeEst)
# storage
numSamples <- 10000
paramSamples <- list(mode='list', length=numSamples)
paramSamples[[1]] <- samp1  # first guy
for(i in 2:numSamples){
print(paste("iter: ", i))
paramSamples[[i]] <- do1Iter(paramSamples[[i-1]], N)
}
if(DOPAR){
stopCluster(cl)
}
proc.time() - ptm
# set to TRUE if you want to do parallel and FALSE otherwise
# set to FALSE if you are on a windows machine
DOPAR <- TRUE
# packages
if (!require("haven")){
install.packages("haven")
library(haven)
}
library(boot) #inv.logit, logit
library(MASS) #mvrnorm
library(mvtnorm)
library(invgamma)
library(mcmcse)
if(DOPAR){ library(parallel) }
# extra functions
source("~/toyota/fully_bayesian_glm_missing_data/mcmc_funcs.R")
# how many cores
if(DOPAR){  no_cores <- detectCores() - 1 }
# read in data
#taylor_data_folder <- "~/Toyota KAB/Data/KAB NASS Query/"
taylor_data_folder <- "~/toyota/"
file <- paste(taylor_data_folder, "kabcombined.sas7bdat", sep = "")
df <- read_sas(file)
df <- as.data.frame(df)
names(df) <- tolower(names(df))
# clean data
dat <- subset(df, select=c("age", "sex", "height", "weight", "seatpos", "dvtotal"))
dat$outcome <- ifelse(df$mais >= 3, 1, 0)
dat$sex <- ifelse(df$sex == 1, 1, 0)
dat$sex <- as.factor(dat$sex)
dat$seatpos <- as.factor(dat$seatpos)
dat <- dat[!is.na(df$mais),] # we remove any row that has a y with an NA #
options(na.action='na.pass') # want model matrix to include missing stuff
X <- model.matrix(~.-outcome, dat)
mis <- is.na(X)
numColsWithMiss <- sum(colSums(mis) != 0)
numMissingEachGroup <- colSums(mis)[colSums(mis) != 0]
# priors for alpha
# recall missing sex1 ~ Bern(p)
# p ~ Beta(shape1P, shape2P)
shape1P <- 100
shape2P <- 100
# recall missing height ~ Normal(alpha2, alpha3)
# alpha2 ~ Normal(alpha2Mean, alpha2Var)
# alpha3 ~ Inversegamma(alpha3Shape, alpha3Rate)
alpha2Mean <- 175
alpha2Var <- 1
alpha3Shape <- 5
alpha3Rate <- 1/(100*alpha3Shape)
# recall weight ~ Normal(alpha4, alpha5)
# alpha4 ~ Normal(alpha4Mean, alpha4Var)
# alpha5 ~ InverseGamma(alpha5Shape, alpha5Rate)
alpha4Mean <- 80
alpha4Var <- 1
alpha5Shape <- 3
alpha5Rate <- 1/(100*alpha5Shape)
# recall dvtotal ~ LogNormal(alpha6, alpha7)
# alpha6 ~ Normal(alpha6Mean, alpha6Var)
# alpha7 ~ InverseGamma(alpha7Shape, alpha7Rate)
alpha6Mean <- 3
alpha6Var <- .1
alpha7Shape <- 3
alpha7Rate <- 1/(.24*alpha7Shape)
# PRIORS FOR BETA (logistic regression coefficients)
meanLogRegIntercept <- -4.75
varIntercept <- 2
varBeta <- 2
# set up the tuning parameters for the proposal
numAlpha <- 7
d <- ncol(X) + numAlpha
alphaQCovMatDiag <- rep(.1, numAlpha)* (2.4^2)/d
#alphaQCovMatDiag <-  c(4.008890e-03, 1.820796e-03, 2.440956e-04, 4.502765e-02, 4.248805e-04, 7.921711e-05, 4.435642e-05)*(2.4^2)/d
betaQCovMat <- vcov(glm(outcome ~ ., data = dat, na.action = na.exclude)) * (2.4^2)/d
logPiUnNorm <- function(alpha, beta){
# calculates the prior for the alpha parameters (govern missing data),
# and for the beta parameters (govern the logistic regression)
nb <- length(beta)
dbeta(x = alpha[1], shape1 = shape1P, shape2 = shape2P, log = TRUE) +
dnorm(x = alpha[2], mean = alpha2Mean, sd = sqrt(alpha2Var), log = TRUE) +
dinvgamma(alpha[3], shape=alpha3Shape, rate = alpha3Rate, log = TRUE) +
dnorm(x = alpha[4], mean = alpha4Mean, sd = sqrt(alpha4Var), log = TRUE) +
dinvgamma(alpha[5], shape=alpha5Shape, rate = alpha5Rate, log = TRUE) +
dnorm(x = alpha[6], mean = alpha6Mean, sd = sqrt(alpha6Var), log = TRUE) +
dinvgamma(alpha[7], shape = alpha7Shape, rate = alpha7Rate, log = TRUE) +
dnorm(x = beta[1], mean = meanLogRegIntercept, sd = sqrt(varIntercept), log = TRUE) +
sum(dnorm(x = beta[2:(nb-1)], mean = 0, sd = sqrt(varBeta), log = TRUE))
}
propose_missdata_given_params <- function(alpha, beta){
# assuming:
# alpha = (p, meanheight, varheight, meanweight, varweight, mudvtotal, sigmaSqdDvTotal)
# beta = (intercept, age, sex1dummy, height, weight, seatpos13, seatpos21, seatpos22, seatpos23, dvtotal)
# draw missing data
# sex ~ bernoulli(alpha1)
# height ~ Normal(alpha2, alpha3)
# weight ~ Normal(alpha4, alpha5)
# dvtotal ~ Lognormal(alpha6, alpha7)
sex <- rbinom(n = numMissingEachGroup[1],
size=1,
alpha[1])
height <- rnorm(n = numMissingEachGroup[2],
mean=alpha[2],
sd = sqrt(alpha[3]))
weight <- rnorm(n = numMissingEachGroup[3],
mean = alpha[4],
sd = sqrt(alpha[5]))
dvtotal <- rlnorm(n = numMissingEachGroup[4],
meanlog = alpha[6],
sdlog = sqrt(alpha[7]))
return(list(sex = sex, height = height, weight = weight, dvtotal = dvtotal))
}
# full model matrix columns are as follows:
# intercept, age, sex1, height, weight, seatpos13, seatpos21, sseatpos22, seatpos23, dvtotal
# the argument here is assumed to be a list of vectors
logCondLike <- function(sex, height, weight, dvtotal, beta){
# insert simulated data into missing data spots
X <- as.data.frame(X)
X$sex1[is.na(X$sex1)] <- sex
X$height[is.na(X$height)] <- height
X$weight[is.na(X$weight)] <- weight
X$dvtotal[is.na(X$dvtotal)] <- dvtotal
stopifnot(sum(is.na(X))==0)
stopifnot(length(beta)==ncol(X))
# evaluate cond like
sum(dbinom(x = dat$outcome,
size = 1,
prob = inv.logit(as.matrix(X) %*% as.matrix(beta)),
log = TRUE))
}
getLogImpSampEst <- function(alphaVec, betaVec, N=100, par = T){
# using log-sum-exp trick
f <- function(purposelessArg){
Xmis <- propose_missdata_given_params(alphaVec, betaVec)
return(logCondLike(sex = Xmis$sex, height=Xmis$height, weight=Xmis$weight, dvtotal=Xmis$dvtotal, beta=betaVec))
}
if(par){
samps <- parSapply(cl, 1:N, f)
}else{
samps <- replicate(N, f())
}
m <- max(samps, na.rm = T)
if(is.infinite(m) && m < 0){
# cat("the maximum log-like was -infinity\n")
return(m)
}
ans <- log(sum(exp(samps - m))) + m - log(N)
# if(is.nan(ans)){
#   cat("ans is nan! ", ans, "\n")
#   cat("samps\n ", samps, "\n")
#   cat("alphas", alphaVec, "\n")
#   cat("betas", betaVec, "\n")
#   # sampleSimData <- f()
#   # cat("sample data:\n ")
#   # for(i in 1:length(sampleSimData)) cat(sampleSimData[[i]], "\n")
# }
return(ans)
}
# alpha = (p, meanheight, varheight, meanweight, varweight, mudvtotal, sigmaSqdDvTotal)
# transAlpha = (logit(p), meanheight, log(varheight), meanweight, log(varweight), mudvtotal, log(varDvTotal))
transAlpha <- function(alpha){
c(logit(alpha[1]), alpha[2], log(alpha[3]), alpha[4], log(alpha[5]), alpha[6], log(alpha[7]))
}
getAlpha <- function(transformedAlpha){
c(inv.logit(transformedAlpha[1]),
transformedAlpha[2],
exp(transformedAlpha[3]),
transformedAlpha[4],
exp(transformedAlpha[5]),
transformedAlpha[6],
exp(transformedAlpha[7]))
}
qSim <- function(oldAlpha, oldBeta){
# sample alphas
newAlpha <- getAlpha(mvrnorm(n=1, mu = transAlpha(oldAlpha), Sigma = diag(alphaQCovMatDiag)))
# sample betas
newBeta <- mvrnorm(n=1, mu=oldBeta, Sigma = betaQCovMat)
# return stuff
list(alphas = newAlpha, betas = newBeta)
}
logQEv <- function(oldAlpha, oldBeta, targetAlpha, targetBeta){
sum(dnorm(x = transAlpha(targetAlpha),
mean = transAlpha(oldAlpha),
sd = sqrt(alphaQCovMatDiag),
log = TRUE)) -
log(targetAlpha[1]) - log(1 - targetAlpha[1]) -
log(targetAlpha[3]) -
log(targetAlpha[5]) -
log(targetAlpha[7]) + # tODO this might be wrong because its the log of the std dev param
dmvnorm(x = targetBeta,
mean = oldBeta,
sigma = betaQCovMat,
log = TRUE)
}
getLogRatio <- function(oldAlpha, oldBeta, oldApproxLogLike, propAlpha, propBeta, propApproxLogLike){
res <- logPiUnNorm(alpha = propAlpha, beta = propBeta) - logPiUnNorm(alpha = oldAlpha, beta = oldBeta)
res <- res + propApproxLogLike - oldApproxLogLike #this can produce NaNs
res <- res + logQEv(oldAlpha = propAlpha, oldBeta = propBeta, targetAlpha = oldAlpha, targetBeta = oldBeta) -
logQEv(oldAlpha = oldAlpha, oldBeta = oldBeta, targetAlpha = propAlpha, targetBeta = propBeta)
return(res)
}
do1Iter <- function(oldSamp, N, par){
propParams <- qSim(oldSamp$alphas, oldSamp$betas)
newApproxLL <- getLogImpSampEst(propParams$alphas, propParams$betas, N, par)
logratio <- getLogRatio(oldAlpha = oldSamp$alphas,
oldBeta = oldSamp$betas,
oldApproxLogLike = oldSamp$LLEst,
propAlpha = propParams$alphas,
propBeta = propParams$betas,
propApproxLogLike = newApproxLL)
if(log(runif(1)) < logratio){
cat("accepting!")
list(alphas = propParams$alphas, betas = propParams$betas, LLEst = newApproxLL)
}else{
oldSamp
}
}
# start off chain here
ptm <- proc.time() # for timing the whole thing
N <- 50 # number of importance samples at each iteration
startAlpha <- c(.53, 171, 30, 74, 68, 3, 1) #(p, meanheight, varheight, meanweight, varweight, mudvtotal, sigmaSqdDvTotal)
startBeta <- coefficients(glm(outcome ~ ., data = dat, na.action = na.exclude))
if(DOPAR){
cl <- makeCluster(no_cores, type="FORK")
clusterExport(cl, list("propose_missdata_given_params"))
}
startLogLikeEst <- getLogImpSampEst(startAlpha, startBeta, N, par = DOPAR)
samp1 <- list(alphas = startAlpha, betas = startBeta, LLEst = startLogLikeEst)
# storage
numSamples <- 10000
paramSamples <- list(mode='list', length=numSamples)
paramSamples[[1]] <- samp1  # first guy
for(i in 2:numSamples){
print(paste("iter: ", i))
paramSamples[[i]] <- do1Iter(paramSamples[[i-1]], N, DOPAR)
}
library(quantmod)
cat("remember: this ignores adjusted close and uses actual prices!")
start <- "2015-10-08" # first day xlre is avialable
symbols <- toupper(sort(c("xlf", "xle", "xlu", "xlk", "xlb", "xlp", "xly", "xli", "xlv", "xlre")))
# get data
options("getSymbols.yahoo.warning"=FALSE)
dfs <- lapply(1:length(symbols),
function(i)
getSymbols(symbols[i], from = start, env = NULL, auto.assign=F))
dfs <- lapply(dfs, function(df) df[xts::.indexwday(df) == 5,] ) # only take fridays
# print out data in expected format
for(i in 1:length(symbols)){
filename <- paste("../weekly_etfs/", symbols[i], ".csv", sep = "")
dt_col <- paste(as.character(index(dfs[[i]])), "00:00:00")
tmp_df <- cbind(dt_col, coredata(dfs[[i]][,1:4]), coredata(dfs[[i]][,1:4]), coredata(dfs[[i]][,5]))
colnames(tmp_df) <- c("period","bid_price_open","bid_price_high","bid_price_low","bid_price_close",
"ask_price_open","ask_price_high","ask_price_low","ask_price_close","volume")
write.csv(tmp_df, filename,  quote = F, row.names = F)
}
traceback()
head(tmp_df)
head(dfs[[1]])
# get data
options("getSymbols.yahoo.warning"=FALSE)
dfs <- lapply(1:length(symbols),
function(i)
getSymbols(symbols[i], from = start, env = NULL, auto.assign=F))
head(dfs[[1]])
dfs <- lapply(dfs, function(df) df[xts::.indexwday(df) == 5,] ) # only take fridays
head(dfs)
head(dfs[[1]])
dfs <- lapply(1:length(symbols),
function(i)
getSymbols(symbols[i], from = start, env = NULL, auto.assign=F))
derp <- lapply(dfs, function(df) df[xts::.indexwday(df) == 5,] ) # only take fridays
wut <- function(df) df[xts::.indexwday(df) == 5,]
wut(dfs[[1]])
xts::.indexwday(dfs[[1]])
table(xts::.indexwday(dfs[[1]]))
head(dfs[[1]])
tail(dfs[[1]])
options("getSymbols.yahoo.warning"=TRUE)
dfs <- lapply(1:length(symbols),
function(i)
getSymbols(symbols[i], from = start, env = NULL, auto.assign=F))
xts::.indexwday
tail(dfs[[1]])
derp <- tail(dfs[[1]])
table(xts::.indxwday(dfs[[1]]))
xts::.indexwday(dfs[[1]])
table(xts::.indexwday(dfs[[1]]))
dfs <- lapply(1:length(symbols),
function(i)
getSymbols(symbols[i], from = start, env = NULL, auto.assign=F))
# I am assuming that
dfs <- lapply(dfs, function(df) df[xts::.indexwday(df) == 4,] ) # only take fridays
head(dfs[1])
head(dfs[[11])
head(dfs[[1]])
# print out data in expected format
for(i in 1:length(symbols)){
filename <- paste("../weekly_etfs/", symbols[i], ".csv", sep = "")
dt_col <- paste(as.character(index(dfs[[i]])), "00:00:00")
tmp_df <- cbind(dt_col, coredata(dfs[[i]][,1:4]), coredata(dfs[[i]][,1:4]), coredata(dfs[[i]][,5]))
colnames(tmp_df) <- c("period","bid_price_open","bid_price_high","bid_price_low","bid_price_close",
"ask_price_open","ask_price_high","ask_price_low","ask_price_close","volume")
write.csv(tmp_df, filename,  quote = F, row.names = F)
}
library(devtools)
?install
install("gradeR/")
install("gradeR/")
gradeR::gradeR()
install()
install("~/gradeR/")
gradeR::gradeR()
test()
setwd("gradeR/")
test()
use_testthat()
test()
use_package_doc()
document()
use_vignette("hello-gradeR")
build_vignettes()
use_readme_rmd()
setwd("example/")
gradeR("assignment1_submissions/", "grade_hw1.R")
gradeR("assignment1_submissions/", "grade_hw1.R")
gradeR("~/gradeR/example/assignment1_submissions/", "~/gradeR/example/grade_hw1.R")
install("~/gradeR/")
gradeR("~/gradeR/example/assignment1_submissions/", "~/gradeR/example/grade_hw1.R")
traceback()
